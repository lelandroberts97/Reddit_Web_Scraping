# Project 3: Skiing vs Snowboarding Web Scraping & NLP

## Problem Statement
Mad River Glen is a ski area in Fayston, Vermont that boasts some of the most challenging skiing on the east coast. They are one of three ski areas that do not allow snowboarders. Each year, snowboarders challenge this policy, and there have been several protests on the mountain. As the data scientist on the crew, I have decided to use natural language processing to determine whether skiiers and snowboarders should be separated, thus providing another justification for why we do not allow them on the mountain. 

## Executive Summary

### Data Gathering
I decided to use r/skiing and r/snowboarding for my two subreddits. The goal was to see if I could build a machine learning model to accurately classify text as being from either r/skiing or r/snowboarding. First, I had to scrape the data from Reddit. I attempted to use the Python Reddit API Wrapper (PRAW) to scrape, but found that I could only get a few hundred text only documents from each subreddit. I also tried to use the requests library, and did obtain more documnts. However, after removing duplicates, I was not able to obtain many additional unique documents. This made me think there was a limit to how much I could scrape from Reddit. This was no good because I needed more than a few hundred documents. Alas, I was shown a website called pushshift.io. They scrape data from Reddit, and have their own database of Reddit posts. I was able to scrape this website to obtain nearly 4000 documents for each subreddit, so I went ahead with these. To make it easier to work with, I placed the information I was interested into a data frame -- one for each subreddit.

### Data Cleaning & EDA
It was a pleasant surprise to find that there were no null or duplicate values in either data frame. This made data cleaning a lot quicker. I did have to remove numeric text and escape characters. I did not remove punctuation because this will be done when vectorizing the text. I also found some documents with the author "AutoModerator." This is a bot built into Reddit, so I removed these documents. Finally, I decided to add a column with the title and text concatenated. I wanted to see if adding the title would add useful information to the models. For exploratory data analysis, I built a few basic models to get an idea of the performance I could expect and what features were important. After vectorizing the data and looking at the most frequent words, I found that words like "skiing", "snowboarding", "ski", and "snowboard" were the most frequent words. I decided to add these to the list of stop words because my goal is to see if there is a difference between skiers and snowboarders besides the words themselves. As to be expected, the decision tree model was highly overfit. The accuracy on the training set was nearly 100%, but it was 63% on the testing set. The logistic regression model had a much lower variance and slightly lower bias, but it still only achieved a 70% accuracy on the testing set. The baseline model was 52%, so neither of these models were great. I also tried stemming and lemmatizing the text to see if that improved model performance. Both did not effect the models very much. The little effect they had was a decrease in performance, so I decided not to stem or lemmatize the text. 

### Modeling
I tried three different models for this project: multinomial naive bayes, random forest, and support vector machine. I grid searched over several hyperparameters for each model to fine tune them. I also tried each model with CountVectorizer and TfidfVectorizer. Overall, the multinomial naive mayes model using CountVectorizer performed the best with a 76% accuracy on the training set and a 75$ accuracy on the testing set. This is very low variance. This is still not a great accuracy though, which makes me think that these two subreddits are not that separable. This could be, at least in part, due to the nature of what people are discussing on each subreddit. They are very similar activities, and when I looked at some of the posts from each subreddit, many were of the same nature. For example, newbies trying to find out what the best gear is and where to ski or ride. Others were discussing conditions and locations, all of which have similar language in either context. I did take a look at feature importance for the random forest model, and found that many of the most important features were brand names specific to each sport as well as common jargon. This is why the model did perform slightly better than baseline.

### Limitations
Both the skiing and snowboarding subreddits had very little text content, and much of the discussion on both subreddits are similar in nature. This is likely why the model did not perform very well. In addition, the goal of the project did not actually support the problem statement. Classifying text as either being from r/skiing and r/snowboarding does not at all prove that snowboarders should not be allowed at Mad River Glen. This was more satirical than serioius.

## Codebooks
- [01 - Web Scraping](https://git.generalassemb.ly/lelandroberts/project_3/blob/master/Code/01_Project_3_Scraping.ipynb)
- [02 - Data Cleaning & EDA](https://git.generalassemb.ly/lelandroberts/project_3/blob/master/Code/02_Project_3_Cleaning_EDA.ipynb)
- [03 - Modeling](https://git.generalassemb.ly/lelandroberts/project_3/blob/master/Code/03_Project_3_Model.ipynb)

## Conclusions & Future Research
Unfortunately, I was not able to draw any conclusions from the models. With a 75% accuracy, it is hard to say whether the two subreddits are different in nature or not. For future research, I would like to try boosting to see if that improves my models. I would also like to get support vector machine working to see how that performs. Lastly, I noticed some remnants of urls in some of the documents, so I would like to remove these. This will remove noise from the models. 

*This project was completed through General Assembly's Data Science Immersive Program.*